{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJJUQNGfU8KS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from catboost) (2.2.3)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from catboost) (5.24.0)\n",
            "Requirement already satisfied: six in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from matplotlib->catboost) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from plotly->catboost) (9.1.2)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "Downloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [optuna]2m3/4\u001b[0m [optuna]\n",
            "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!pip install catboost\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "#sklearn\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# set paths for preprocessor\n",
        "sys.path.append('/content/drive/MyDrive/Erdos/Project/summer-2025-hoax-detection/')\n",
        "\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "from feature_engineer import (\n",
        "    VandalismScorer,\n",
        "    is_IP,\n",
        "    account_age,\n",
        "    comment_empty,\n",
        "    word_count,\n",
        "    preprocessor\n",
        ")\n",
        "#optuna\n",
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N8YrQWNbVBmB"
      },
      "outputs": [],
      "source": [
        "#read the dataset\n",
        "df = pd.read_csv(\"Data/train.csv\")\n",
        "preprocessor(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.4.0'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optuna.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AJbZuiKDVFK-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline accuracy score: 0.9152\n"
          ]
        }
      ],
      "source": [
        "#Baseline Score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.features]\n",
        "\n",
        "\n",
        "nfeatures = [\n",
        "    'user_edit_count', 'user_distinct_pages', 'user_warns', 'num_edits_5d_before',\n",
        "    'is_person', 'current_minor', 'account_age', 'comment_empty',\n",
        "    'is_IP', 'word_count_added', 'word_count_deleted', 'vandalism_score'\n",
        "]\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scorer', VandalismScorer(n_splits=5, random_state=42)),\n",
        "    ('select', FeatureSelector(nfeatures)),\n",
        "    ('model', CatBoostClassifier(random_state=42, verbose=0))\n",
        "])\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "baseline_score = cross_val_score(\n",
        "    pipe, df.copy(), df['isvandalism'].copy(),\n",
        "    cv=cv, scoring='accuracy'\n",
        ").mean()\n",
        "\n",
        "print(f\"Baseline accuracy score: {baseline_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n7ZtyHjlU2Kc"
      },
      "outputs": [],
      "source": [
        "def get_oof_vandalism_score(predictor, target, cv, scorer_args=None):\n",
        "    scorer_args = scorer_args or {}\n",
        "    df_oof = predictor.copy()\n",
        "    df_oof[\"vandalism_score\"] = np.nan\n",
        "\n",
        "    for train_idx, val_idx in cv.split(predictor, target):\n",
        "        X_train, X_val = predictor.iloc[train_idx], predictor.iloc[val_idx]\n",
        "        y_train = target.iloc[train_idx]\n",
        "\n",
        "        scorer = VandalismScorer(**scorer_args)\n",
        "        scorer.fit(X_train, y_train)\n",
        "        X_val_transformed = scorer.transform(X_val)\n",
        "\n",
        "        df_oof.loc[val_idx, \"vandalism_score\"] = X_val_transformed[\"vandalism_score\"].values\n",
        "\n",
        "    return df_oof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.model_selection import cross_val_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lPb23JjDU5TR"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    predictor: pd.DataFrame,\n",
        "    target: pd.Series,\n",
        "    cv: StratifiedKFold,\n",
        "    scoring: str = \"accuracy\",\n",
        ") -> None:\n",
        "\n",
        "    # Step 1: Precompute vandalism_score safely\n",
        "    predictor_with_score = get_oof_vandalism_score(\n",
        "        predictor,\n",
        "        target,\n",
        "        cv,\n",
        "        scorer_args={\"n_splits\": 5, \"random_state\": 42}\n",
        "    )\n",
        "\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
        "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-2, 10.0, log=True),\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
        "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "            \"random_strength\": trial.suggest_float(\"random_strength\", 1e-3, 10.0, log=True),\n",
        "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
        "            \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
        "            \"verbose\": 0,\n",
        "            \"random_state\": 42,\n",
        "        }\n",
        "\n",
        "        nfeatures = [\n",
        "            'user_edit_count', 'user_distinct_pages', 'user_warns', 'num_edits_5d_before',\n",
        "            'is_person', 'current_minor', 'account_age', 'comment_empty',\n",
        "            'is_IP', 'word_count_added', 'word_count_deleted', 'vandalism_score'\n",
        "        ]\n",
        "\n",
        "        model = CatBoostClassifier(**params)\n",
        "        preds = cross_val_predict(\n",
        "            model, predictor_with_score[nfeatures], target, cv=cv\n",
        "            )\n",
        "        acc = accuracy_score(target, preds)\n",
        "        f1 = f1_score(target, preds)\n",
        "\n",
        "        print(f\"Trial {trial.number}: Accuracy={acc:.4f}, F1={f1:.4f}, Params={params}\")\n",
        "\n",
        "\n",
        "        return acc\n",
        "\n",
        "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=25)\n",
        "\n",
        "    print(\"Optuna Optimization Results\")\n",
        "    print(\"Best Accuracy:\", study.best_value)\n",
        "    print(\"Best hyperparameters:\", study.best_params)\n",
        "\n",
        "    return study.best_params, study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sOrHPs4PVJ0c"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "target = [\"isvandalism\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JNEEC4LNVK_8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0: Accuracy=0.9216, F1=0.9193, Params={'depth': 4, 'l2_leaf_reg': 4.035046715075941, 'learning_rate': 0.07152156324850309, 'iterations': 606, 'subsample': 0.6626283533430583, 'random_strength': 0.13042781462724903, 'bagging_temperature': 0.011361335367422565, 'border_count': 96, 'verbose': 0, 'random_state': 42}\n",
            "Trial 1: Accuracy=0.9116, F1=0.9099, Params={'depth': 4, 'l2_leaf_reg': 0.5219428452355841, 'learning_rate': 0.024773925767558224, 'iterations': 196, 'subsample': 0.720812702679729, 'random_strength': 0.0010479197011280372, 'bagging_temperature': 0.7362828460170855, 'border_count': 57, 'verbose': 0, 'random_state': 42}\n",
            "Trial 2: Accuracy=0.9138, F1=0.9114, Params={'depth': 8, 'l2_leaf_reg': 2.822993241009302, 'learning_rate': 0.22819503487735865, 'iterations': 664, 'subsample': 0.6398902509658554, 'random_strength': 0.037446758967447494, 'bagging_temperature': 0.8766658736258968, 'border_count': 63, 'verbose': 0, 'random_state': 42}\n",
            "Trial 3: Accuracy=0.9108, F1=0.9095, Params={'depth': 4, 'l2_leaf_reg': 1.8766362190253743, 'learning_rate': 0.015911533623519866, 'iterations': 375, 'subsample': 0.7820605190090737, 'random_strength': 5.868102336841363, 'bagging_temperature': 0.9084083700723938, 'border_count': 66, 'verbose': 0, 'random_state': 42}\n",
            "Trial 4: Accuracy=0.9185, F1=0.9164, Params={'depth': 6, 'l2_leaf_reg': 0.06533740568694277, 'learning_rate': 0.013990434704144104, 'iterations': 399, 'subsample': 0.813632412674763, 'random_strength': 0.10558484991111791, 'bagging_temperature': 0.3508425043775357, 'border_count': 33, 'verbose': 0, 'random_state': 42}\n",
            "Trial 5: Accuracy=0.9204, F1=0.9182, Params={'depth': 6, 'l2_leaf_reg': 0.17578412708196775, 'learning_rate': 0.022748310028399887, 'iterations': 398, 'subsample': 0.7175861467942645, 'random_strength': 0.0014725671712551506, 'bagging_temperature': 0.13394624366680286, 'border_count': 47, 'verbose': 0, 'random_state': 42}\n",
            "Trial 6: Accuracy=0.9197, F1=0.9175, Params={'depth': 7, 'l2_leaf_reg': 0.0401643955347681, 'learning_rate': 0.049571736449230616, 'iterations': 207, 'subsample': 0.7782027399192334, 'random_strength': 0.0036044508759372853, 'bagging_temperature': 0.0751549902715718, 'border_count': 93, 'verbose': 0, 'random_state': 42}\n",
            "Trial 7: Accuracy=0.9195, F1=0.9172, Params={'depth': 5, 'l2_leaf_reg': 0.9669165066509003, 'learning_rate': 0.11970246506290298, 'iterations': 574, 'subsample': 0.622008049685097, 'random_strength': 0.004504766838455965, 'bagging_temperature': 0.7469934207099341, 'border_count': 142, 'verbose': 0, 'random_state': 42}\n",
            "Trial 8: Accuracy=0.9144, F1=0.9123, Params={'depth': 8, 'l2_leaf_reg': 1.4066293445993883, 'learning_rate': 0.016622585519499185, 'iterations': 172, 'subsample': 0.8544875091554415, 'random_strength': 0.4635567456895378, 'bagging_temperature': 0.9893856086068847, 'border_count': 133, 'verbose': 0, 'random_state': 42}\n",
            "Trial 9: Accuracy=0.9199, F1=0.9176, Params={'depth': 8, 'l2_leaf_reg': 0.01431257095883684, 'learning_rate': 0.010042315462133461, 'iterations': 863, 'subsample': 0.745684341688704, 'random_strength': 0.0010371156049900014, 'bagging_temperature': 0.15555298843195964, 'border_count': 83, 'verbose': 0, 'random_state': 42}\n",
            "Trial 10: Accuracy=0.9221, F1=0.9199, Params={'depth': 5, 'l2_leaf_reg': 8.560784680088616, 'learning_rate': 0.06937838204628097, 'iterations': 946, 'subsample': 0.9983256117930293, 'random_strength': 1.4558080187311846, 'bagging_temperature': 0.4341844339107094, 'border_count': 229, 'verbose': 0, 'random_state': 42}\n",
            "Trial 11: Accuracy=0.9215, F1=0.9193, Params={'depth': 5, 'l2_leaf_reg': 9.88946853870947, 'learning_rate': 0.06842598557481946, 'iterations': 1000, 'subsample': 0.9849708892198382, 'random_strength': 1.9990502300031945, 'bagging_temperature': 0.4262781257739277, 'border_count': 239, 'verbose': 0, 'random_state': 42}\n",
            "Trial 12: Accuracy=0.9220, F1=0.9197, Params={'depth': 5, 'l2_leaf_reg': 8.85253622532518, 'learning_rate': 0.05819780080631019, 'iterations': 760, 'subsample': 0.9855644380068462, 'random_strength': 0.530968880013139, 'bagging_temperature': 0.28972727443307145, 'border_count': 216, 'verbose': 0, 'random_state': 42}\n",
            "Trial 13: Accuracy=0.9218, F1=0.9196, Params={'depth': 5, 'l2_leaf_reg': 8.679752960643789, 'learning_rate': 0.04126192559746591, 'iterations': 805, 'subsample': 0.9957892372409215, 'random_strength': 0.8020469248949061, 'bagging_temperature': 0.2930774745065945, 'border_count': 227, 'verbose': 0, 'random_state': 42}\n",
            "Trial 14: Accuracy=0.9203, F1=0.9182, Params={'depth': 5, 'l2_leaf_reg': 5.043795166542716, 'learning_rate': 0.13089880132211576, 'iterations': 817, 'subsample': 0.9181983554708917, 'random_strength': 5.74816801140361, 'bagging_temperature': 0.5561814219061623, 'border_count': 196, 'verbose': 0, 'random_state': 42}\n",
            "Trial 15: Accuracy=0.9175, F1=0.9152, Params={'depth': 6, 'l2_leaf_reg': 0.48643142548395446, 'learning_rate': 0.09693206246732733, 'iterations': 998, 'subsample': 0.9218058854919104, 'random_strength': 0.7169284190885574, 'bagging_temperature': 0.5518450505494098, 'border_count': 189, 'verbose': 0, 'random_state': 42}\n",
            "Trial 16: Accuracy=0.9206, F1=0.9183, Params={'depth': 7, 'l2_leaf_reg': 0.18782421324458504, 'learning_rate': 0.0343365558567313, 'iterations': 698, 'subsample': 0.9232796898118034, 'random_strength': 0.03673229547861975, 'bagging_temperature': 0.2668786570592476, 'border_count': 255, 'verbose': 0, 'random_state': 42}\n",
            "Trial 17: Accuracy=0.9187, F1=0.9164, Params={'depth': 5, 'l2_leaf_reg': 4.650814129028497, 'learning_rate': 0.1812813902928975, 'iterations': 906, 'subsample': 0.8741726934356385, 'random_strength': 0.28113548368974234, 'bagging_temperature': 0.4651620839250842, 'border_count': 191, 'verbose': 0, 'random_state': 42}\n",
            "Trial 18: Accuracy=0.9207, F1=0.9184, Params={'depth': 6, 'l2_leaf_reg': 0.8810580341136319, 'learning_rate': 0.06823717292203453, 'iterations': 755, 'subsample': 0.9574002769417599, 'random_strength': 1.9536813655970517, 'bagging_temperature': 0.6751605244332999, 'border_count': 215, 'verbose': 0, 'random_state': 42}\n",
            "Trial 19: Accuracy=0.9215, F1=0.9194, Params={'depth': 4, 'l2_leaf_reg': 2.303959618989527, 'learning_rate': 0.034140113127033724, 'iterations': 936, 'subsample': 0.8838320988607953, 'random_strength': 2.356525877151219, 'bagging_temperature': 0.21078876808963853, 'border_count': 164, 'verbose': 0, 'random_state': 42}\n",
            "Trial 20: Accuracy=0.9173, F1=0.9150, Params={'depth': 7, 'l2_leaf_reg': 9.103688780003115, 'learning_rate': 0.29302287888947415, 'iterations': 495, 'subsample': 0.9657110807728013, 'random_strength': 0.0384826268484452, 'bagging_temperature': 0.3729762487347481, 'border_count': 167, 'verbose': 0, 'random_state': 42}\n",
            "Trial 21: Accuracy=0.9215, F1=0.9193, Params={'depth': 5, 'l2_leaf_reg': 7.268065116766565, 'learning_rate': 0.04699954193584319, 'iterations': 789, 'subsample': 0.99946492225944, 'random_strength': 0.9992035979415599, 'bagging_temperature': 0.2915292285856554, 'border_count': 224, 'verbose': 0, 'random_state': 42}\n",
            "Trial 22: Accuracy=0.9215, F1=0.9194, Params={'depth': 5, 'l2_leaf_reg': 3.6991362122211773, 'learning_rate': 0.03778409491283874, 'iterations': 724, 'subsample': 0.9586612158793207, 'random_strength': 0.2989082237837137, 'bagging_temperature': 0.3034877573332242, 'border_count': 255, 'verbose': 0, 'random_state': 42}\n",
            "Trial 23: Accuracy=0.9215, F1=0.9193, Params={'depth': 5, 'l2_leaf_reg': 5.868609298003444, 'learning_rate': 0.091527005157423, 'iterations': 857, 'subsample': 0.995784176480025, 'random_strength': 0.929914178530537, 'bagging_temperature': 0.5123590949081438, 'border_count': 218, 'verbose': 0, 'random_state': 42}\n",
            "Trial 24: Accuracy=0.9221, F1=0.9199, Params={'depth': 4, 'l2_leaf_reg': 9.790198694010789, 'learning_rate': 0.05760859964554447, 'iterations': 891, 'subsample': 0.938723795858982, 'random_strength': 3.351393580697412, 'bagging_temperature': 0.21479999800641322, 'border_count': 232, 'verbose': 0, 'random_state': 42}\n",
            "Optuna Optimization Results\n",
            "Best Accuracy: 0.9221330816422841\n",
            "Best hyperparameters: {'depth': 4, 'l2_leaf_reg': 9.790198694010789, 'learning_rate': 0.05760859964554447, 'iterations': 891, 'subsample': 0.938723795858982, 'random_strength': 3.351393580697412, 'bagging_temperature': 0.21479999800641322, 'border_count': 232}\n"
          ]
        }
      ],
      "source": [
        "best_params, best_score = train(df, df.isvandalism, cv)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hoax-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
