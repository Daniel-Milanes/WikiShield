{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fJJUQNGfU8KS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (1.16.2)\n",
            "Requirement already satisfied: colorlog in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/envs/hoax-detection/lib/python3.12/site-packages (from lightgbm) (1.15.3)\n",
            "Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightgbm\n",
            "Successfully installed lightgbm-4.6.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "#sklearn\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# set paths for preprocessor\n",
        "sys.path.append('/content/drive/MyDrive/Erdos/Project/summer-2025-hoax-detection/')\n",
        "\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "from feature_engineer import (\n",
        "    VandalismScorer,\n",
        "    is_IP,\n",
        "    account_age,\n",
        "    comment_empty,\n",
        "    word_count,\n",
        "    preprocessor\n",
        ")\n",
        "#optuna\n",
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "!pip install lightgbm\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N8YrQWNbVBmB"
      },
      "outputs": [],
      "source": [
        "#read the dataset\n",
        "df = pd.read_csv(\"../Data/train.csv\")\n",
        "preprocessor(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AJbZuiKDVFK-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline accuracy score: 0.9140\n"
          ]
        }
      ],
      "source": [
        "#Baseline Score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.features]\n",
        "\n",
        "\n",
        "nfeatures = [\n",
        "    'user_edit_count', 'user_distinct_pages', 'user_warns', 'num_edits_5d_before',\n",
        "    'is_person', 'current_minor', 'account_age', 'comment_empty',\n",
        "    'is_IP', 'word_count_added', 'word_count_deleted', 'vandalism_score'\n",
        "]\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scorer', VandalismScorer(n_splits=5, random_state=42)),\n",
        "    ('select', FeatureSelector(nfeatures)),\n",
        "    ('model', LGBMClassifier(objective='binary',\n",
        "              metric='binary_logloss',\n",
        "              verbosity = -1,\n",
        "              boosting_type='gbdt',\n",
        "              force_col_wise=True,\n",
        "              random_state=42))\n",
        "])\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "baseline_score = cross_val_score(\n",
        "    pipe, df.copy(), df['isvandalism'].copy(),\n",
        "    cv=cv, scoring='accuracy'\n",
        ").mean()\n",
        "\n",
        "print(f\"Baseline accuracy score: {baseline_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n7ZtyHjlU2Kc"
      },
      "outputs": [],
      "source": [
        "def get_oof_vandalism_score(predictor, target, cv, scorer_args=None):\n",
        "    scorer_args = scorer_args or {}\n",
        "    df_oof = predictor.copy()\n",
        "    df_oof[\"vandalism_score\"] = np.nan\n",
        "\n",
        "    for train_idx, val_idx in cv.split(predictor, target):\n",
        "        X_train, X_val = predictor.iloc[train_idx], predictor.iloc[val_idx]\n",
        "        y_train = target.iloc[train_idx]\n",
        "\n",
        "        scorer = VandalismScorer(**scorer_args)\n",
        "        scorer.fit(X_train, y_train)\n",
        "        X_val_transformed = scorer.transform(X_val)\n",
        "\n",
        "        df_oof.loc[val_idx, \"vandalism_score\"] = X_val_transformed[\"vandalism_score\"].values\n",
        "\n",
        "    return df_oof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lPb23JjDU5TR"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    predictor: pd.DataFrame,\n",
        "    target: pd.Series,\n",
        "    cv: StratifiedKFold,\n",
        "    scoring: str = \"accuracy\",\n",
        ") -> None:\n",
        "\n",
        "    # Step 1: Precompute vandalism_score safely\n",
        "    predictor_with_score = get_oof_vandalism_score(\n",
        "        predictor,\n",
        "        target,\n",
        "        cv,\n",
        "        scorer_args={\"n_splits\": 5, \"random_state\": 42}\n",
        "    )\n",
        "\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'objective': 'binary',\n",
        "            'metric': 'binary_logloss',\n",
        "            'verbosity': -1,\n",
        "            'boosting_type': 'gbdt',\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
        "            'num_leaves': trial.suggest_int('num_leaves', 15, 256),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        nfeatures = [\n",
        "            'user_edit_count', 'user_distinct_pages', 'user_warns', 'num_edits_5d_before',\n",
        "            'is_person', 'current_minor', 'account_age', 'comment_empty',\n",
        "            'is_IP', 'word_count_added', 'word_count_deleted', 'vandalism_score'\n",
        "        ]\n",
        "\n",
        "        model = LGBMClassifier(**params)\n",
        "        preds = cross_val_predict(\n",
        "            model, predictor_with_score[nfeatures], target, cv=cv\n",
        "            )\n",
        "        acc = accuracy_score(target, preds)\n",
        "        f1 = f1_score(target, preds)\n",
        "\n",
        "        print(f\"Trial {trial.number}: Accuracy={acc:.4f}, F1={f1:.4f}, Params={params}\")\n",
        "\n",
        "\n",
        "        return acc\n",
        "\n",
        "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=25)\n",
        "\n",
        "    print(\"Optuna Optimization Results\")\n",
        "    print(\"Best Accuracy:\", study.best_value)\n",
        "    print(\"Best hyperparameters:\", study.best_params)\n",
        "\n",
        "    return study.best_params, study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sOrHPs4PVJ0c"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JNEEC4LNVK_8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0: Accuracy=0.9150, F1=0.9127, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.1243197447568749, 'num_leaves': 134, 'n_estimators': 671, 'max_depth': 9, 'random_state': 42}\n",
            "Trial 1: Accuracy=0.9207, F1=0.9185, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.02620304020717626, 'num_leaves': 215, 'n_estimators': 863, 'max_depth': 5, 'random_state': 42}\n",
            "Trial 2: Accuracy=0.9128, F1=0.9094, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.0016713397078052061, 'num_leaves': 210, 'n_estimators': 376, 'max_depth': 9, 'random_state': 42}\n",
            "Trial 3: Accuracy=0.9184, F1=0.9162, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.024734133899256164, 'num_leaves': 212, 'n_estimators': 530, 'max_depth': 12, 'random_state': 42}\n",
            "Trial 4: Accuracy=0.9150, F1=0.9123, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.0017306454556788795, 'num_leaves': 219, 'n_estimators': 850, 'max_depth': 12, 'random_state': 42}\n",
            "Trial 5: Accuracy=0.9164, F1=0.9138, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.003990039629522147, 'num_leaves': 182, 'n_estimators': 769, 'max_depth': 8, 'random_state': 42}\n",
            "Trial 6: Accuracy=0.9126, F1=0.9103, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.2585033410560283, 'num_leaves': 46, 'n_estimators': 705, 'max_depth': 8, 'random_state': 42}\n",
            "Trial 7: Accuracy=0.9131, F1=0.9107, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.24837474775006593, 'num_leaves': 242, 'n_estimators': 632, 'max_depth': 8, 'random_state': 42}\n",
            "Trial 8: Accuracy=0.9035, F1=0.9008, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.0022718269802543627, 'num_leaves': 162, 'n_estimators': 602, 'max_depth': 5, 'random_state': 42}\n",
            "Trial 9: Accuracy=0.9187, F1=0.9164, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.010137071755935841, 'num_leaves': 65, 'n_estimators': 695, 'max_depth': 8, 'random_state': 42}\n",
            "Trial 10: Accuracy=0.9204, F1=0.9181, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.042132870576764174, 'num_leaves': 115, 'n_estimators': 972, 'max_depth': 5, 'random_state': 42}\n",
            "Trial 11: Accuracy=0.9202, F1=0.9180, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.039575885188261654, 'num_leaves': 116, 'n_estimators': 998, 'max_depth': 5, 'random_state': 42}\n",
            "Trial 12: Accuracy=0.9180, F1=0.9159, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.06134100822475002, 'num_leaves': 95, 'n_estimators': 998, 'max_depth': 6, 'random_state': 42}\n",
            "Trial 13: Accuracy=0.9087, F1=0.9059, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.01270251343851647, 'num_leaves': 162, 'n_estimators': 111, 'max_depth': 6, 'random_state': 42}\n",
            "Trial 14: Accuracy=0.9197, F1=0.9175, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.07069384084618627, 'num_leaves': 16, 'n_estimators': 898, 'max_depth': 6, 'random_state': 42}\n",
            "Trial 15: Accuracy=0.9114, F1=0.9091, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.007278330687990253, 'num_leaves': 96, 'n_estimators': 459, 'max_depth': 5, 'random_state': 42}\n",
            "Trial 16: Accuracy=0.9194, F1=0.9171, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.025065417037581427, 'num_leaves': 255, 'n_estimators': 858, 'max_depth': 7, 'random_state': 42}\n",
            "Trial 17: Accuracy=0.9175, F1=0.9153, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.09833003879331652, 'num_leaves': 177, 'n_estimators': 261, 'max_depth': 10, 'random_state': 42}\n",
            "Trial 18: Accuracy=0.9175, F1=0.9153, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.037411222717588746, 'num_leaves': 131, 'n_estimators': 914, 'max_depth': 7, 'random_state': 42}\n",
            "Trial 19: Accuracy=0.9191, F1=0.9168, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.006108765686025462, 'num_leaves': 79, 'n_estimators': 784, 'max_depth': 11, 'random_state': 42}\n",
            "Trial 20: Accuracy=0.9206, F1=0.9183, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.01708637780823757, 'num_leaves': 158, 'n_estimators': 802, 'max_depth': 7, 'random_state': 42}\n",
            "Trial 21: Accuracy=0.9199, F1=0.9175, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.018491470506188164, 'num_leaves': 160, 'n_estimators': 796, 'max_depth': 6, 'random_state': 42}\n",
            "Trial 22: Accuracy=0.9181, F1=0.9159, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.045329264246001734, 'num_leaves': 192, 'n_estimators': 966, 'max_depth': 7, 'random_state': 42}\n",
            "Trial 23: Accuracy=0.9211, F1=0.9189, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.01636772317002149, 'num_leaves': 112, 'n_estimators': 918, 'max_depth': 5, 'random_state': 42}\n",
            "Trial 24: Accuracy=0.9210, F1=0.9188, Params={'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.01673003438164171, 'num_leaves': 149, 'n_estimators': 760, 'max_depth': 6, 'random_state': 42}\n",
            "Optuna Optimization Results\n",
            "Best Accuracy: 0.9210712600283153\n",
            "Best hyperparameters: {'learning_rate': 0.01636772317002149, 'num_leaves': 112, 'n_estimators': 918, 'max_depth': 5}\n"
          ]
        }
      ],
      "source": [
        "best_params, best_score = train(df, df.isvandalism, cv)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hoax-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
