{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef46078",
   "metadata": {},
   "source": [
    "# Decision tree, random forest, extra tree implementation, with logistic regression as a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98214bb",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eee775",
   "metadata": {},
   "source": [
    "Import the data and set up the features, cross-validation, and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "features = [\"user_edit_count\", \"user_warns\", \"num_recent_reversions\", \"num_edits_5d_before\", \"is_person\"]\n",
    "\n",
    "num_splits = 5\n",
    "num_models = 4\n",
    "kfold = StratifiedKFold(num_splits, random_state=216, shuffle=True)\n",
    "\n",
    "## This array will hold the mse for each model and split. Change to other metrics as needed.\n",
    "rmses = np.zeros((num_models, num_splits))\n",
    "\n",
    "## This array will hold the accuracy scores.\n",
    "accs = np.zeros(num_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0c4a7",
   "metadata": {},
   "source": [
    "Fit the models and record the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sets a split counter to help record the metrics\n",
    "i = 0\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[features], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    log_reg = LogisticRegression(penalty=None, max_iter=500) # Note that sufficient iteration is needed\n",
    "    log_reg.fit(df_tt[features], df_tt.isvandalism)\n",
    "    log_pred = log_reg.predict(df_ho[features])\n",
    "\n",
    "    rmses[0, i] = root_mean_squared_error(df_ho.isvandalism, log_pred)\n",
    "\n",
    "\n",
    "    tree = DecisionTreeClassifier(\n",
    "        #max_depth = 10, \n",
    "        min_samples_leaf = 5, # minimum number of samples in each leaf, to prevent overfitting\n",
    "        random_state= 216\n",
    "        )\n",
    "    tree.fit(df_tt[features], df_tt.isvandalism)\n",
    "    tree_pred = tree.predict(df_ho[features])\n",
    "\n",
    "    rmses[1, i] = root_mean_squared_error(df_ho.isvandalism, tree_pred)\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators = 500, # number of trees in ensemble\n",
    "        #max_depth = 10, # max_depth of each tree\n",
    "        min_samples_leaf = 5, \n",
    "        #max_features = 2, # default is round(sqrt(num_features))\n",
    "        bootstrap= True, # sampling with replacement\n",
    "        max_samples = 500, # number of training samples selected with replacement to build tree\n",
    "        random_state = 216 # for consistency\n",
    "        )\n",
    "    \n",
    "    rf.fit(df_tt[features], df_tt.isvandalism)\n",
    "    rf_pred = rf.predict(df_ho[features])\n",
    "\n",
    "    rmses[2, i] = root_mean_squared_error(df_ho.isvandalism, rf_pred)\n",
    "\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators = 500, \n",
    "        #max_depth = 10, \n",
    "        min_samples_leaf = 5, \n",
    "        #max_features = 2, \n",
    "        bootstrap= True, \n",
    "        max_samples = 500, \n",
    "        random_state = 216 \n",
    "        )\n",
    "    \n",
    "    et.fit(df_tt[features], df_tt.isvandalism)\n",
    "    et_pred = et.predict(df_ho[features])\n",
    "\n",
    "    rmses[3, i] = root_mean_squared_error(df_ho.isvandalism, et_pred)\n",
    "\n",
    "    acc = np.array([accuracy_score(df_ho.isvandalism, log_pred), accuracy_score(df_ho.isvandalism, tree_pred),  accuracy_score(df_ho.isvandalism, rf_pred), accuracy_score(df_ho.isvandalism, et_pred)])\n",
    "    accs = accs + acc\n",
    "\n",
    "    score_df = pd.DataFrame({'feature':df_tt[features].columns,\n",
    "                            'importance_score': rf.feature_importances_})\n",
    "\n",
    "    score_df.sort_values('importance_score',ascending=False)\n",
    "    print(score_df)\n",
    "    \n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "# Calculate the average accuracy scores over the splits\n",
    "accs = accs / num_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b134a3f",
   "metadata": {},
   "source": [
    "Print out (average) accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ad116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(accs, index= ['log', 'tree', 'rf', 'et'], columns = ['avg_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3401b0a",
   "metadata": {},
   "source": [
    "Print out the RMSEs (change to other metrics if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb66bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Logistic Regression Avg. CV RMSE: {np.mean(rmses[0,:])} and STD: {np.std(rmses[0,:])}\")\n",
    "print(f\"Decision Tree Avg. CV MSE: {np.mean(rmses[1,:])} and STD: {np.std(rmses[1,:])}\")\n",
    "print(f\"Random Forest Avg. CV MSE: {np.mean(rmses[2,:])} and STD: {np.std(rmses[2,:])}\")\n",
    "print(f\"Extra Tree Avg. CV MSE: {np.mean(rmses[3,:])} and STD: {np.std(rmses[3,:])}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
