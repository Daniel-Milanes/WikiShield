{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef46078",
   "metadata": {},
   "source": [
    "# Decision tree, random forest, extra tree implementation, with logistic regression as a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98214bb",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd194d3d",
   "metadata": {},
   "source": [
    "Prepare for preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically add the project root (1 level up) to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from feature_engineer import preprocessor, VandalismScorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcfd95",
   "metadata": {},
   "source": [
    "Read in the train data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33762fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(project_root+\"/data/train.csv\")\n",
    "preprocessor(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30daa42c",
   "metadata": {},
   "source": [
    "Raw features including add_lines and deleted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"EditID\", \"user_edit_count\", \"user_warns\", \"num_recent_reversions\", \"num_edits_5d_before\", \"is_person\", \"added_lines\", \"deleted_lines\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eee775",
   "metadata": {},
   "source": [
    "Initialize the cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 5\n",
    "num_models = 4\n",
    "kfold = StratifiedKFold(num_splits, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723dc02",
   "metadata": {},
   "source": [
    "Define functions that tune the models using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective functions for the models\n",
    "def objective_logreg(trial, X, y):\n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('log', LogisticRegression(C=C, solver=solver, penalty='l2', max_iter=500))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "def objective_tree(trial, X, y):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('tree', DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "def objective_rf(trial, X, y):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('rf', RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "def objective_et(trial, X, y):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('et', ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "## --------- Functions to run tuning for each model ---------\n",
    "def tune_model(objective_fn, X, y, n_trials=3):  # for runtime reason we only do 3 trials (so runtime for 15 trials in total needed for the 5-fold cross-validation for each model)\n",
    "    def obj(trial):\n",
    "        return objective_fn(trial, X, y)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj, n_trials=n_trials)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0c4a7",
   "metadata": {},
   "source": [
    "Tune and fit the models, and record the metric results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ba892",
   "metadata": {},
   "source": [
    "A naive logistic regression with no hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05049fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_logreg, f1s_logreg = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    logistic_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('log', LogisticRegression(max_iter=500, penalty=None))\n",
    "    ])\n",
    "    logistic_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    log_pred = logistic_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(df_ho['isvandalism'], log_pred)\n",
    "    f1 = f1_score(df_ho['isvandalism'], log_pred)\n",
    "    accs_logreg.append(acc)\n",
    "    f1s_logreg.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1578c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accs_logreg)\n",
    "print(f1s_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48895302",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f46098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-26 20:38:27,559] A new study created in memory with name: no-name-d7c0114c-5ba4-49d7-91c2-c755bec60cd5\n",
      "[I 2025-06-26 20:40:45,171] Trial 0 finished with value: 0.8285811170287968 and parameters: {'C': 64.6198033948995, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8285811170287968.\n",
      "[I 2025-06-26 20:43:18,224] Trial 1 finished with value: 0.8314322423533742 and parameters: {'C': 0.022524555913570145, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.8314322423533742.\n",
      "[I 2025-06-26 20:45:47,493] Trial 2 finished with value: 0.7745550824017075 and parameters: {'C': 0.0015336617889900332, 'solver': 'liblinear'}. Best is trial 1 with value: 0.8314322423533742.\n",
      "[I 2025-06-26 20:47:01,884] A new study created in memory with name: no-name-a2c9c902-318a-4850-8b1b-42d9e968717a\n",
      "[I 2025-06-26 20:49:11,061] Trial 0 finished with value: 0.8259263295253366 and parameters: {'C': 0.05481854518515586, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8259263295253366.\n",
      "[I 2025-06-26 20:51:22,001] Trial 1 finished with value: 0.8245498621937605 and parameters: {'C': 0.8501144813542324, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8259263295253366.\n",
      "[I 2025-06-26 20:53:35,716] Trial 2 finished with value: 0.7326730060291952 and parameters: {'C': 0.0011267395869916695, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8259263295253366.\n",
      "[I 2025-06-26 20:54:36,769] A new study created in memory with name: no-name-478102db-92a1-4d20-851a-c915a634fce3\n",
      "[I 2025-06-26 20:56:57,119] Trial 0 finished with value: 0.8194379953125432 and parameters: {'C': 290.72927601499146, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8194379953125432.\n",
      "[I 2025-06-26 20:59:18,416] Trial 1 finished with value: 0.8339885999358785 and parameters: {'C': 0.5669942406710837, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.8339885999358785.\n",
      "[I 2025-06-26 21:01:40,300] Trial 2 finished with value: 0.8194379953125432 and parameters: {'C': 0.03012115433826083, 'solver': 'liblinear'}. Best is trial 1 with value: 0.8339885999358785.\n",
      "[I 2025-06-26 21:02:48,079] A new study created in memory with name: no-name-0e89f8cc-1db5-423c-b340-6865b24165b5\n",
      "[I 2025-06-26 21:04:58,841] Trial 0 finished with value: 0.8056825443641548 and parameters: {'C': 0.015014217378442298, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8056825443641548.\n",
      "[I 2025-06-26 21:06:59,638] Trial 1 finished with value: 0.8386177063363319 and parameters: {'C': 0.00207537782482641, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.8386177063363319.\n",
      "[I 2025-06-26 21:09:00,464] Trial 2 finished with value: 0.8262301528781398 and parameters: {'C': 564.4024604069607, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.8386177063363319.\n",
      "[I 2025-06-26 21:10:02,111] A new study created in memory with name: no-name-4706c175-d7cd-490e-9e4e-2dafddfda7df\n",
      "[I 2025-06-26 21:12:15,572] Trial 0 finished with value: 0.8304084943223713 and parameters: {'C': 0.5037700238112482, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8304084943223713.\n",
      "[I 2025-06-26 21:14:23,661] Trial 1 finished with value: 0.7358796637664061 and parameters: {'C': 0.3642632973084576, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8304084943223713.\n",
      "[I 2025-06-26 21:16:27,974] Trial 2 finished with value: 0.830261023447869 and parameters: {'C': 1.55905856985891, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8304084943223713.\n"
     ]
    }
   ],
   "source": [
    "accs_logreg, f1s_logreg = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    logreg_params = tune_model(objective_logreg, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    logistic_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('log', LogisticRegression(max_iter=500, **logreg_params))\n",
    "    ])\n",
    "    logistic_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    log_pred = logistic_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(df_ho['isvandalism'], log_pred)\n",
    "    f1 = f1_score(df_ho['isvandalism'], log_pred)\n",
    "    accs_logreg.append(acc)\n",
    "    f1s_logreg.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902831",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63291f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-26 21:19:12,980] A new study created in memory with name: no-name-002e92fd-3b75-41c6-b6a4-5b959de4cdfd\n",
      "[I 2025-06-26 21:21:21,766] Trial 0 finished with value: 0.8957821734828807 and parameters: {'max_depth': 8, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8957821734828807.\n",
      "[I 2025-06-26 21:23:32,918] Trial 1 finished with value: 0.8794611715857701 and parameters: {'max_depth': 14, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8957821734828807.\n",
      "[I 2025-06-26 21:25:43,988] Trial 2 finished with value: 0.8737095537200724 and parameters: {'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8957821734828807.\n",
      "[I 2025-06-26 21:26:47,753] A new study created in memory with name: no-name-e6701ee9-5a5d-4f63-a142-17b11d540c29\n",
      "[I 2025-06-26 21:28:54,032] Trial 0 finished with value: 0.8856059798642079 and parameters: {'max_depth': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8856059798642079.\n",
      "[I 2025-06-26 21:31:00,605] Trial 1 finished with value: 0.8901285215196547 and parameters: {'max_depth': 7, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8901285215196547.\n",
      "[I 2025-06-26 21:33:09,726] Trial 2 finished with value: 0.8767082586734842 and parameters: {'max_depth': 15, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8901285215196547.\n",
      "[I 2025-06-26 21:34:20,539] A new study created in memory with name: no-name-e9211f6a-ced3-4027-a3cd-7115b9b4fd92\n",
      "[I 2025-06-26 21:36:43,663] Trial 0 finished with value: 0.9004029855529295 and parameters: {'max_depth': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9004029855529295.\n",
      "[I 2025-06-26 21:39:06,470] Trial 1 finished with value: 0.8887520831892338 and parameters: {'max_depth': 12, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9004029855529295.\n",
      "[I 2025-06-26 21:41:26,795] Trial 2 finished with value: 0.8744468138388294 and parameters: {'max_depth': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9004029855529295.\n",
      "[I 2025-06-26 21:42:38,360] A new study created in memory with name: no-name-b3d8249e-b253-47ba-8e40-f1264538cca2\n",
      "[I 2025-06-26 21:44:57,077] Trial 0 finished with value: 0.8814825738583295 and parameters: {'max_depth': 14, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8814825738583295.\n",
      "[I 2025-06-26 21:47:17,510] Trial 1 finished with value: 0.8859558570515657 and parameters: {'max_depth': 11, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.8859558570515657.\n",
      "[I 2025-06-26 21:49:30,817] Trial 2 finished with value: 0.8985400383424272 and parameters: {'max_depth': 6, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8985400383424272.\n",
      "[I 2025-06-26 21:50:32,361] A new study created in memory with name: no-name-5b33fc21-eda7-4e43-b380-5dd6c6498566\n",
      "[I 2025-06-26 21:52:43,359] Trial 0 finished with value: 0.8836946369758639 and parameters: {'max_depth': 19, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8836946369758639.\n",
      "[I 2025-06-26 21:55:03,442] Trial 1 finished with value: 0.8880204492945977 and parameters: {'max_depth': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8880204492945977.\n",
      "[I 2025-06-26 21:57:21,022] Trial 2 finished with value: 0.8944600108145307 and parameters: {'max_depth': 10, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.8944600108145307.\n"
     ]
    }
   ],
   "source": [
    "accs_tree, f1s_tree = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    tree_params = tune_model(objective_tree, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    tree_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('tree', DecisionTreeClassifier(random_state=42, **tree_params))\n",
    "    ])\n",
    "    tree_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    tree_pred = tree_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(df_ho['isvandalism'], tree_pred)\n",
    "    f1 = f1_score(df_ho['isvandalism'], tree_pred)\n",
    "    accs_tree.append(acc)\n",
    "    f1s_tree.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f401304",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02136410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-26 21:59:31,004] A new study created in memory with name: no-name-d7910f05-1dbb-4538-8425-c3332bb44446\n",
      "[I 2025-06-26 22:01:42,605] Trial 0 finished with value: 0.8945530537708969 and parameters: {'max_depth': 9, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8945530537708969.\n",
      "[I 2025-06-26 22:03:54,620] Trial 1 finished with value: 0.8988789965948293 and parameters: {'max_depth': 17, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 1 with value: 0.8988789965948293.\n",
      "[I 2025-06-26 22:06:03,758] Trial 2 finished with value: 0.8966176605145065 and parameters: {'max_depth': 13, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 1 with value: 0.8988789965948293.\n",
      "[I 2025-06-26 22:07:19,967] A new study created in memory with name: no-name-81a7946b-a4ac-4c02-8b07-91ae53da575a\n",
      "[I 2025-06-26 22:09:46,157] Trial 0 finished with value: 0.8888996918192236 and parameters: {'max_depth': 11, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.8888996918192236.\n",
      "[I 2025-06-26 22:12:14,647] Trial 1 finished with value: 0.8911120231974441 and parameters: {'max_depth': 19, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 1 with value: 0.8911120231974441.\n",
      "[I 2025-06-26 22:14:37,154] Trial 2 finished with value: 0.8891946553190947 and parameters: {'max_depth': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 1 with value: 0.8911120231974441.\n",
      "[I 2025-06-26 22:15:48,098] A new study created in memory with name: no-name-930f08f0-7ed4-4667-b7ca-aeb012525258\n",
      "[I 2025-06-26 22:18:10,406] Trial 0 finished with value: 0.8975518167266192 and parameters: {'max_depth': 12, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 0 with value: 0.8975518167266192.\n",
      "[I 2025-06-26 22:20:28,235] Trial 1 finished with value: 0.8970600078854142 and parameters: {'max_depth': 6, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 0.8975518167266192.\n",
      "[I 2025-06-26 22:22:49,182] Trial 2 finished with value: 0.8970601166397464 and parameters: {'max_depth': 14, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8975518167266192.\n",
      "[I 2025-06-26 22:23:59,989] A new study created in memory with name: no-name-c4169800-2085-4692-ae8e-6ab5c114fcb1\n",
      "[I 2025-06-26 22:26:18,673] Trial 0 finished with value: 0.8938701273165216 and parameters: {'max_depth': 8, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.8938701273165216.\n",
      "[I 2025-06-26 22:28:29,834] Trial 1 finished with value: 0.8745514427567223 and parameters: {'max_depth': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8938701273165216.\n",
      "[I 2025-06-26 22:30:39,571] Trial 2 finished with value: 0.8977535270117484 and parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 2 with value: 0.8977535270117484.\n",
      "[I 2025-06-26 22:31:47,166] A new study created in memory with name: no-name-8809d382-6ff2-4c18-9b94-0a8142c38529\n",
      "[I 2025-06-26 22:33:58,857] Trial 0 finished with value: 0.8938209703583543 and parameters: {'max_depth': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8938209703583543.\n",
      "[I 2025-06-26 22:35:57,219] Trial 1 finished with value: 0.898146782677088 and parameters: {'max_depth': 13, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.898146782677088.\n",
      "[I 2025-06-26 22:37:53,531] Trial 2 finished with value: 0.8951973651870423 and parameters: {'max_depth': 9, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 1 with value: 0.898146782677088.\n"
     ]
    }
   ],
   "source": [
    "accs_rf, f1s_rf = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    rf_params = tune_model(objective_rf, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    rf_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('rf', RandomForestClassifier(\n",
    "            n_estimators=100,  # You can increase after tuning for production\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **rf_params\n",
    "        ))\n",
    "    ])\n",
    "    rf_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    rf_pred = rf_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(df_ho['isvandalism'], rf_pred)\n",
    "    f1 = f1_score(df_ho['isvandalism'], rf_pred)\n",
    "    accs_rf.append(acc)\n",
    "    f1s_rf.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31177c7",
   "metadata": {},
   "source": [
    "Extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100a64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-26 22:52:38,867] A new study created in memory with name: no-name-d88c6246-8731-4b68-ad18-31f2a8ffd380\n",
      "[I 2025-06-26 22:54:55,798] Trial 0 finished with value: 0.8664829225972217 and parameters: {'max_depth': 17, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 0.8664829225972217.\n",
      "[I 2025-06-26 22:56:48,341] Trial 1 finished with value: 0.7955952102852017 and parameters: {'max_depth': 8, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.8664829225972217.\n",
      "[I 2025-06-26 22:58:40,906] Trial 2 finished with value: 0.8068035840207695 and parameters: {'max_depth': 7, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 0.8664829225972217.\n",
      "[I 2025-06-26 22:59:36,727] A new study created in memory with name: no-name-e9156889-4e3d-4bca-a76c-0b9ca7a5454c\n",
      "[I 2025-06-26 23:01:25,988] Trial 0 finished with value: 0.8486871974545106 and parameters: {'max_depth': 12, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 0.8486871974545106.\n",
      "[I 2025-06-26 23:03:15,814] Trial 1 finished with value: 0.7948086917042341 and parameters: {'max_depth': 4, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.8486871974545106.\n",
      "[I 2025-06-26 23:05:05,509] Trial 2 finished with value: 0.788466769823776 and parameters: {'max_depth': 2, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 0 with value: 0.8486871974545106.\n",
      "[I 2025-06-26 23:06:02,101] A new study created in memory with name: no-name-709671cd-ecb1-43f8-9ed2-2b212bf651a9\n",
      "[I 2025-06-26 23:07:57,123] Trial 0 finished with value: 0.7982989009867208 and parameters: {'max_depth': 18, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7982989009867208.\n",
      "[I 2025-06-26 23:09:52,352] Trial 1 finished with value: 0.7995771269048503 and parameters: {'max_depth': 4, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 1 with value: 0.7995771269048503.\n",
      "[I 2025-06-26 23:11:50,665] Trial 2 finished with value: 0.7980531306964614 and parameters: {'max_depth': 11, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 1 with value: 0.7995771269048503.\n",
      "[I 2025-06-26 23:12:49,605] A new study created in memory with name: no-name-6d1cd9ef-a642-4ba2-814f-7ae2be7ec2f1\n",
      "[I 2025-06-26 23:14:42,665] Trial 0 finished with value: 0.7947696996509857 and parameters: {'max_depth': 2, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.7947696996509857.\n",
      "[I 2025-06-26 23:16:36,510] Trial 1 finished with value: 0.7990955119697193 and parameters: {'max_depth': 8, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 1 with value: 0.7990955119697193.\n",
      "[I 2025-06-26 23:18:33,508] Trial 2 finished with value: 0.7962444083960084 and parameters: {'max_depth': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 1 with value: 0.7990955119697193.\n",
      "[I 2025-06-26 23:19:35,217] A new study created in memory with name: no-name-0e5af954-49bc-44ce-ab6c-bdca1db79fad\n",
      "[I 2025-06-26 23:21:26,000] Trial 0 finished with value: 0.7993412967605563 and parameters: {'max_depth': 15, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7993412967605563.\n",
      "[I 2025-06-26 23:23:15,029] Trial 1 finished with value: 0.8007668485474119 and parameters: {'max_depth': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.8007668485474119.\n",
      "[I 2025-06-26 23:25:04,172] Trial 2 finished with value: 0.8049451899916433 and parameters: {'max_depth': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.8049451899916433.\n"
     ]
    }
   ],
   "source": [
    "accs_et, f1s_et = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    et_params = tune_model(objective_et, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    et_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('et', ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **et_params\n",
    "        ))\n",
    "    ])\n",
    "    et_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    et_pred = et_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(df_ho['isvandalism'], et_pred)\n",
    "    f1 = f1_score(df_ho['isvandalism'], et_pred)\n",
    "    accs_et.append(acc)\n",
    "    f1s_et.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b134a3f",
   "metadata": {},
   "source": [
    "Print out (average) accuracy scores and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d042e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg:   accuracy=0.8360, F1=0.8395\n",
      "Tree:     accuracy=0.9014, F1=0.8970\n",
      "RF:       accuracy=0.8999, F1=0.8957\n",
      "ET:       accuracy=0.8263, F1=0.7943\n"
     ]
    }
   ],
   "source": [
    "print(f\"LogReg:   accuracy={sum(accs_logreg)/len(accs_logreg):.4f}, F1={sum(f1s_logreg)/len(f1s_logreg):.4f}\")\n",
    "print(f\"Tree:     accuracy={sum(accs_tree)/len(accs_tree):.4f}, F1={sum(f1s_tree)/len(f1s_tree):.4f}\")\n",
    "print(f\"RF:       accuracy={sum(accs_rf)/len(accs_rf):.4f}, F1={sum(f1s_rf)/len(f1s_rf):.4f}\")\n",
    "print(f\"ET:       accuracy={sum(accs_et)/len(accs_et):.4f}, F1={sum(f1s_et)/len(f1s_et):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoax-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
