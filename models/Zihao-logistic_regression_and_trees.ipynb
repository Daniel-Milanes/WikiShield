{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef46078",
   "metadata": {},
   "source": [
    "# Logistic regression, decision tree, random forest, extra tree implementations and optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98214bb",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5da0db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd194d3d",
   "metadata": {},
   "source": [
    "Prepare for preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fbc7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically add the project root (1 level up) to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from feature_engineer import preprocessor, VandalismScorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcfd95",
   "metadata": {},
   "source": [
    "Read in the train data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33762fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(project_root+\"/data/train.csv\")\n",
    "preprocessor(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30daa42c",
   "metadata": {},
   "source": [
    "Raw features including add_lines and deleted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82dc1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"EditID\", \"user_edit_count\", \"user_warns\", \"num_recent_reversions\", \"num_edits_5d_before\", \"is_person\", \"added_lines\", \"deleted_lines\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76aea8",
   "metadata": {},
   "source": [
    "Tune and fit the models, and record the metric results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48895302",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a312f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(\n",
    "    predictor: pd.DataFrame,\n",
    "    target: pd.Series,\n",
    "    cv: StratifiedKFold,\n",
    "    scoring: str = \"accuracy\",\n",
    "    n_trials: int = 10\n",
    "):\n",
    "    baseline_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('logreg', LogisticRegression(max_iter=500, random_state=42))\n",
    "    ])\n",
    "    baseline_score = cross_val_score(\n",
    "        baseline_model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "    print(f\"Baseline {scoring} score: {baseline_score:.4f}\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"lbfgs\", \"liblinear\"]),\n",
    "            \"penalty\": \"l2\",\n",
    "            \"max_iter\": 500,\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "        model = Pipeline([\n",
    "            ('scorer', VandalismScorer(n_splits=5)),\n",
    "            ('logreg', LogisticRegression(**params))\n",
    "        ])\n",
    "        score = cross_val_score(model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1).mean()\n",
    "        return score\n",
    "\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Optuna Optimization Results\")\n",
    "    print(\"Best Accuracy:\", study.best_value)\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "    # Final evaluation\n",
    "    best_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('logreg', LogisticRegression(**study.best_params))\n",
    "    ])\n",
    "    y_pred = cross_val_predict(best_model, predictor, target, cv=cv, n_jobs=-1)\n",
    "    # All metrics\n",
    "    accuracy = accuracy_score(target, y_pred)\n",
    "    f1 = f1_score(target, y_pred)\n",
    "    precision = precision_score(target, y_pred)\n",
    "    recall = recall_score(target, y_pred)\n",
    "\n",
    "    print(f\"\\nBest-tuned Logistic Regression metrics (cv mean):\")\n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"F1       : {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "\n",
    "    return study.best_params, study.best_value, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = train_logreg(\n",
    "    predictor=df_train[feature_cols],\n",
    "    target=df_train[\"isvandalism\"],\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda9ade",
   "metadata": {},
   "source": [
    "Logistic regression results before tuning threshold:\n",
    "\n",
    "Baseline accuracy score: 0.8333\n",
    "Optuna Optimization Results\n",
    "Best Accuracy: 0.843715886167941\n",
    "Best hyperparameters: {'C': 0.0029799440180166927, 'solver': 'lbfgs'}\n",
    "\n",
    "Best-tuned Logistic Regression metrics (cv mean):\n",
    "Accuracy : 0.8438\n",
    "F1       : 0.8503\n",
    "Precision: 0.7967\n",
    "Recall   : 0.9117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb144f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43\n",
      "F1      : 0.8491\n",
      "Accuracy: 0.8348\n",
      "Precision: 0.7646\n",
      "Recall  : 0.9547\n"
     ]
    }
   ],
   "source": [
    "best_param_log = {'C': 0.0029799440180166927, 'solver': 'lbfgs', 'max_iter': 500, 'random_state': 42, 'penalty': 'l2'}\n",
    "best_logreg = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('log', LogisticRegression(**best_param_log))\n",
    "    ])\n",
    "\n",
    "oof_proba = np.zeros(len(df_train))\n",
    "oof_index = np.zeros(len(df_train), dtype=bool)\n",
    "\n",
    "for train_idx, valid_idx in cv.split(df_train[feature_cols], df_train['isvandalism']):\n",
    "    X_train = df_train.iloc[train_idx][feature_cols]\n",
    "    y_train = df_train.iloc[train_idx]['isvandalism']        \n",
    "    X_valid = df_train.iloc[valid_idx][feature_cols]\n",
    "\n",
    "    best_logreg.fit(X_train, y_train)\n",
    "    oof_proba[valid_idx] = best_logreg.predict_proba(X_valid)[:, 1]\n",
    "    oof_index[valid_idx] = True\n",
    "\n",
    "assert oof_index.all()  \n",
    "\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "y_true = df_train['isvandalism']\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (oof_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "\n",
    "y_pred = (oof_proba >= best_thresh).astype(int)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Best threshold: {best_thresh:.2f}\")\n",
    "print(f\"F1      : {f1:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall  : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90214f24",
   "metadata": {},
   "source": [
    "Logistic regression results after tunning threshold to maximize F1 score:\n",
    "\n",
    "Best threshold: 0.43\n",
    "F1      : 0.8491\n",
    "Accuracy: 0.8348\n",
    "Precision: 0.7646\n",
    "Recall  : 0.9547"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba438a4",
   "metadata": {},
   "source": [
    "Note that the F1 score after tuning (to maximze F1) seems lower than before tuning. This is because tuning the threshold globally on OOF probabilities is intrinsically different from averaging per-fold F1 score (where in each fold only a part of the data is used)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902831",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63291f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tree(\n",
    "    predictor: pd.DataFrame,\n",
    "    target: pd.Series,\n",
    "    cv: StratifiedKFold,\n",
    "    scoring: str = \"accuracy\",\n",
    "    n_trials: int = 10\n",
    "):\n",
    "\n",
    "    baseline_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('tree', DecisionTreeClassifier(random_state=42))\n",
    "    ])\n",
    "    baseline_score = cross_val_score(\n",
    "        baseline_model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "    print(f\"Baseline {scoring} score: {baseline_score:.4f}\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"]),\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "        model = Pipeline([\n",
    "            ('scorer', VandalismScorer(n_splits=5)),\n",
    "            ('tree', DecisionTreeClassifier(**params))\n",
    "        ])\n",
    "        score = cross_val_score(model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1).mean()\n",
    "        return score\n",
    "\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Optuna Optimization Results\")\n",
    "    print(\"Best Accuracy:\", study.best_value)\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "    best_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('tree', DecisionTreeClassifier(**study.best_params))\n",
    "    ])\n",
    "    y_pred = cross_val_predict(best_model, predictor, target, cv=cv, n_jobs=-1)\n",
    "    accuracy = accuracy_score(target, y_pred)\n",
    "    f1 = f1_score(target, y_pred)\n",
    "    precision = precision_score(target, y_pred)\n",
    "    recall = recall_score(target, y_pred)\n",
    "\n",
    "    print(f\"\\nBest-tuned Decision Tree metrics (cv mean):\")\n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"F1       : {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "\n",
    "    return study.best_params, study.best_value, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b2bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy score: 0.8680\n",
      "Optuna Optimization Results\n",
      "Best Accuracy: 0.899009137234841\n",
      "Best hyperparameters: {'max_depth': 7, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "\n",
      "Best-tuned Decision Tree metrics (cv mean):\n",
      "Accuracy : 0.8990\n",
      "F1       : 0.8945\n",
      "Precision: 0.9103\n",
      "Recall   : 0.8793\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = train_tree(\n",
    "    predictor=df_train[feature_cols],\n",
    "    target=df_train[\"isvandalism\"],\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3f31e",
   "metadata": {},
   "source": [
    "Decision tree results before tuning threshold:\n",
    "\n",
    "Baseline accuracy score: 0.8680\n",
    "Optuna Optimization Results\n",
    "Best Accuracy: 0.899009137234841\n",
    "Best hyperparameters: {'max_depth': 7, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
    "\n",
    "Best-tuned Decision Tree metrics (cv mean):\n",
    "Accuracy : 0.8990\n",
    "F1       : 0.8945\n",
    "Precision: 0.9103\n",
    "Recall   : 0.8793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1e29177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.40\n",
      "F1      : 0.8969\n",
      "Accuracy: 0.8992\n",
      "Precision: 0.8938\n",
      "Recall  : 0.9000\n"
     ]
    }
   ],
   "source": [
    "best_param_tree = {'max_depth': 7, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}\n",
    "best_tree = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('tree', DecisionTreeClassifier(**best_param_tree))\n",
    "    ])\n",
    "\n",
    "oof_proba = np.zeros(len(df_train))\n",
    "oof_index = np.zeros(len(df_train), dtype=bool)\n",
    "\n",
    "for train_idx, valid_idx in cv.split(df_train[feature_cols], df_train['isvandalism']):\n",
    "    X_train = df_train.iloc[train_idx][feature_cols]\n",
    "    y_train = df_train.iloc[train_idx]['isvandalism']\n",
    "    X_valid = df_train.iloc[valid_idx][feature_cols]\n",
    "\n",
    "    best_tree.fit(X_train, y_train)\n",
    "    oof_proba[valid_idx] = best_tree.predict_proba(X_valid)[:, 1]\n",
    "    oof_index[valid_idx] = True\n",
    "\n",
    "assert oof_index.all()  \n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "y_true = df_train['isvandalism']\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (oof_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "\n",
    "y_pred = (oof_proba >= best_thresh).astype(int)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Best threshold: {best_thresh:.2f}\")\n",
    "print(f\"F1      : {f1:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall  : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551791a",
   "metadata": {},
   "source": [
    "Decision tree results after tuning threshold to maximize F1 score:\n",
    "\n",
    "Best threshold: 0.40\n",
    "F1      : 0.8969\n",
    "Accuracy: 0.8992\n",
    "Precision: 0.8938\n",
    "Recall  : 0.9000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f401304",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02136410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(\n",
    "    predictor: pd.DataFrame,\n",
    "    target: pd.Series,\n",
    "    cv: StratifiedKFold,\n",
    "    scoring: str = \"accuracy\",\n",
    "    n_trials: int = 10\n",
    "):\n",
    "\n",
    "    baseline_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('rf', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "    baseline_score = cross_val_score(\n",
    "        baseline_model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "    print(f\"Baseline {scoring} score: {baseline_score:.4f}\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_samples\": 500,\n",
    "            \"bootstrap\": True,\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", ['sqrt', 'log2', None]),\n",
    "            \"criterion\": \"gini\",\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "        model = Pipeline([\n",
    "            ('scorer', VandalismScorer(n_splits=5)),\n",
    "            ('rf', RandomForestClassifier(**params))\n",
    "        ])\n",
    "        score = cross_val_score(model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1).mean()\n",
    "        return score\n",
    "\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Optuna Optimization Results\")\n",
    "    print(\"Best Accuracy:\", study.best_value)\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "    best_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('rf', RandomForestClassifier(**study.best_params))\n",
    "    ])\n",
    "    y_pred = cross_val_predict(best_model, predictor, target, cv=cv, n_jobs=-1)\n",
    "    accuracy = accuracy_score(target, y_pred)\n",
    "    f1 = f1_score(target, y_pred)\n",
    "    precision = precision_score(target, y_pred)\n",
    "    recall = recall_score(target, y_pred)\n",
    "\n",
    "    print(f\"\\nBest-tuned Random Forest metrics (cv mean):\")\n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"F1       : {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "\n",
    "    return study.best_params, study.best_value, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "851f261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy score: 0.8921\n",
      "Optuna Optimization Results\n",
      "Best Accuracy: 0.8986553173324424\n",
      "Best hyperparameters: {'max_depth': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "\n",
      "Best-tuned Random Forest metrics (cv mean):\n",
      "Accuracy : 0.9001\n",
      "F1       : 0.8952\n",
      "Precision: 0.9153\n",
      "Recall   : 0.8760\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = train_rf(\n",
    "    predictor=df_train[feature_cols],\n",
    "    target=df_train[\"isvandalism\"],\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67dcfe",
   "metadata": {},
   "source": [
    "Random forest results before tuning threshold:\n",
    "\n",
    "Baseline accuracy score: 0.8921\n",
    "Optuna Optimization Results\n",
    "Best Accuracy: 0.8986553173324424\n",
    "Best hyperparameters: {'max_depth': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
    "\n",
    "Best-tuned Random Forest metrics (cv mean):\n",
    "Accuracy : 0.9001\n",
    "F1       : 0.8952\n",
    "Precision: 0.9153\n",
    "Recall   : 0.8760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d676796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Forest] Best threshold: 0.45\n",
      "F1      : 0.8978\n",
      "Accuracy: 0.8990\n",
      "Precision: 0.8850\n",
      "Recall  : 0.9109\n"
     ]
    }
   ],
   "source": [
    "best_param_rf = {'max_depth': 8, 'min_samples_leaf': 2, 'max_features': 'log2', \"n_estimators\": 100,\n",
    "            \"max_samples\": 500,\n",
    "            \"bootstrap\": True,\n",
    "            \"criterion\": \"gini\",\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,}\n",
    "best_rf = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('rf', RandomForestClassifier(**best_param_rf))\n",
    "    ])\n",
    "\n",
    "oof_proba = np.zeros(len(df_train))\n",
    "oof_index = np.zeros(len(df_train), dtype=bool)\n",
    "\n",
    "for train_idx, valid_idx in cv.split(df_train[feature_cols], df_train['isvandalism']):\n",
    "    X_train = df_train.iloc[train_idx][feature_cols]\n",
    "    y_train = df_train.iloc[train_idx]['isvandalism']\n",
    "    X_valid = df_train.iloc[valid_idx][feature_cols]\n",
    "\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    oof_proba[valid_idx] = best_rf.predict_proba(X_valid)[:, 1]\n",
    "    oof_index[valid_idx] = True\n",
    "\n",
    "assert oof_index.all()\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "y_true = df_train['isvandalism']\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (oof_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "y_pred = (oof_proba >= best_thresh).astype(int)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Best threshold: {best_thresh:.2f}\")\n",
    "print(f\"F1      : {f1:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall  : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a5a61",
   "metadata": {},
   "source": [
    "Random forest results after tuning threshold:\n",
    "\n",
    "Best threshold: 0.45\n",
    "F1      : 0.8978\n",
    "Accuracy: 0.8990\n",
    "Precision: 0.8850\n",
    "Recall  : 0.9109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31177c7",
   "metadata": {},
   "source": [
    "# Extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4100a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_et(\n",
    "    predictor: pd.DataFrame,\n",
    "    target: pd.Series,\n",
    "    cv: StratifiedKFold,\n",
    "    scoring: str = \"accuracy\",\n",
    "    n_trials: int = 10\n",
    "):\n",
    "\n",
    "    baseline_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('et', ExtraTreesClassifier(random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "    baseline_score = cross_val_score(\n",
    "        baseline_model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "    print(f\"Baseline {scoring} score: {baseline_score:.4f}\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": None, # previous optimization suggests that larger max_depth gives better accuracy\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", ['sqrt', 'log2', None]),\n",
    "            \"criterion\": \"gini\",\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "        model = Pipeline([\n",
    "            ('scorer', VandalismScorer(n_splits=5)),\n",
    "            ('et', ExtraTreesClassifier(**params))\n",
    "        ])\n",
    "        score = cross_val_score(model, predictor, target, cv=cv, scoring=scoring, n_jobs=-1).mean()\n",
    "        return score\n",
    "\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Optuna Optimization Results\")\n",
    "    print(\"Best Accuracy:\", study.best_value)\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "    best_model = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('et', ExtraTreesClassifier(**study.best_params))\n",
    "    ])\n",
    "    y_pred = cross_val_predict(best_model, predictor, target, cv=cv, n_jobs=-1)\n",
    "    accuracy = accuracy_score(target, y_pred)\n",
    "    f1 = f1_score(target, y_pred)\n",
    "    precision = precision_score(target, y_pred)\n",
    "    recall = recall_score(target, y_pred)\n",
    "\n",
    "    print(f\"\\nBest-tuned Extra Trees metrics (cv mean):\")\n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"F1       : {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "\n",
    "    return study.best_params, study.best_value, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = train_et(\n",
    "    predictor=df_train[feature_cols],\n",
    "    target=df_train[\"isvandalism\"],\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30059d8d",
   "metadata": {},
   "source": [
    "Extra tree results before tuning threshold:\n",
    "\n",
    "Baseline accuracy score: 0.8827\n",
    "Optuna Optimization Results\n",
    "Best Accuracy: 0.895784398222742\n",
    "Best hyperparameters: {'min_samples_leaf': 2, 'max_features': None}\n",
    "\n",
    "Best-tuned Extra Trees metrics (cv mean):\n",
    "Accuracy : 0.8961\n",
    "F1       : 0.8917\n",
    "Precision: 0.9049\n",
    "Recall   : 0.8788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4f8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Extra Trees] Best threshold: 0.41\n",
      "F1      : 0.8950\n",
      "Accuracy: 0.8961\n",
      "Precision: 0.8803\n",
      "Recall  : 0.9103\n"
     ]
    }
   ],
   "source": [
    "best_param_et = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": None,\n",
    "            \"min_samples_leaf\": 2,\n",
    "            \"max_features\": None,\n",
    "            \"criterion\": \"gini\",\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "best_et = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=5)),\n",
    "        ('et', ExtraTreesClassifier(**best_param_et))\n",
    "    ])\n",
    "\n",
    "oof_proba = np.zeros(len(df_train))\n",
    "oof_index = np.zeros(len(df_train), dtype=bool)\n",
    "\n",
    "for train_idx, valid_idx in cv.split(df_train[feature_cols], df_train['isvandalism']):\n",
    "    X_train = df_train.iloc[train_idx][feature_cols]\n",
    "    y_train = df_train.iloc[train_idx]['isvandalism']\n",
    "    X_valid = df_train.iloc[valid_idx][feature_cols]\n",
    "\n",
    "    best_et.fit(X_train, y_train)\n",
    "    oof_proba[valid_idx] = best_et.predict_proba(X_valid)[:, 1]\n",
    "    oof_index[valid_idx] = True\n",
    "\n",
    "assert oof_index.all()\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "y_true = df_train['isvandalism']\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (oof_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "y_pred = (oof_proba >= best_thresh).astype(int)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Best threshold: {best_thresh:.2f}\")\n",
    "print(f\"F1      : {f1:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall  : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe696acc",
   "metadata": {},
   "source": [
    "Extra tree results after tuning threshold to maximize F1 score:\n",
    "\n",
    "Best threshold: 0.41\n",
    "F1      : 0.8950\n",
    "Accuracy: 0.8961\n",
    "Precision: 0.8803\n",
    "Recall  : 0.9103"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoax-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
