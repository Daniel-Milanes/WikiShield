{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef46078",
   "metadata": {},
   "source": [
    "# Decision tree, random forest, extra tree implementation, with logistic regression as a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98214bb",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd194d3d",
   "metadata": {},
   "source": [
    "Prepare for preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically add the project root (1 level up) to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from feature_engineer import preprocessor, VandalismScorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcfd95",
   "metadata": {},
   "source": [
    "Read in the train data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33762fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(project_root+\"/data/train.csv\")\n",
    "preprocessor(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30daa42c",
   "metadata": {},
   "source": [
    "Raw features including add_lines and deleted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"user_edit_count\", \"user_warns\", \"num_recent_reversions\", \"num_edits_5d_before\", \"is_person\", \"added_lines\", \"deleted_lines\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eee775",
   "metadata": {},
   "source": [
    "Initialize the cross-validation and metric records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 5\n",
    "num_models = 4\n",
    "kfold = StratifiedKFold(num_splits, random_state=42, shuffle=True)\n",
    "\n",
    "## This array will hold the mse for each model and split. Change to other metrics as needed.\n",
    "rmses = np.zeros((num_models, num_splits))\n",
    "\n",
    "## This array will hold the accuracy scores.\n",
    "accs = np.zeros(num_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723dc02",
   "metadata": {},
   "source": [
    "Define functions that tune the models using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c628b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective functions for the models\n",
    "def objective_logreg(trial, X, y):\n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('log', LogisticRegression(C=C, solver=solver, penalty='l2', max_iter=500))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "def objective_tree(trial, X, y):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('tree', DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "def objective_rf(trial, X, y):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('rf', RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "def objective_et(trial, X, y):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('et', ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    return cross_val_score(pipe, X, y, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "## --------- Functions to run tuning for each model ---------\n",
    "def tune_model(objective_fn, X, y, n_trials=15):\n",
    "    def obj(trial):\n",
    "        return objective_fn(trial, X, y)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj, n_trials=n_trials)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0c4a7",
   "metadata": {},
   "source": [
    "Tune and fit the models, and record the metric results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48895302",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f46098",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_logreg, f1s_logreg = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    logreg_params = tune_model(objective_logreg, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    logistic_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('log', LogisticRegression(max_iter=500, **logreg_params))\n",
    "    ])\n",
    "    logistic_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    log_pred = logistic_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(y_ho, log_pred)\n",
    "    f1 = f1_score(y_ho, log_pred)\n",
    "    accs_logreg.append(acc)\n",
    "    f1s_logreg.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902831",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63291f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_tree, f1s_tree = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    tree_params = tune_model(objective_tree, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    tree_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('tree', DecisionTreeClassifier(random_state=42, **tree_params))\n",
    "    ])\n",
    "    tree_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    tree_pred = tree_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(y_ho, tree_pred)\n",
    "    f1 = f1_score(y_ho, tree_pred)\n",
    "    accs_tree.append(acc)\n",
    "    f1s_tree.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f401304",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02136410",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_rf, f1s_rf = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    rf_params = tune_model(objective_rf, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    rf_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('rf', RandomForestClassifier(\n",
    "            n_estimators=100,  # You can increase after tuning for production\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **rf_params\n",
    "        ))\n",
    "    ])\n",
    "    rf_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    rf_pred = rf_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(y_ho, rf_pred)\n",
    "    f1 = f1_score(y_ho, rf_pred)\n",
    "    accs_rf.append(acc)\n",
    "    f1s_rf.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31177c7",
   "metadata": {},
   "source": [
    "Extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_et, f1s_et = [], []\n",
    "\n",
    "## loop through the kfold here\n",
    "for train_index, test_index in kfold.split(df_train[feature_cols], df_train.isvandalism):\n",
    "    ## cv training set\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "\n",
    "    ## cv holdout set\n",
    "    df_ho = df_train.iloc[test_index]\n",
    "\n",
    "    et_params = tune_model(objective_et, df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    et_pipe = Pipeline([\n",
    "        ('scorer', VandalismScorer(n_splits=4)),\n",
    "        ('et', ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            bootstrap=True,\n",
    "            max_samples=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **et_params\n",
    "        ))\n",
    "    ])\n",
    "    et_pipe.fit(df_tt[feature_cols], df_tt['isvandalism'])\n",
    "    et_pred = et_pipe.predict(df_ho[feature_cols])\n",
    "    acc = accuracy_score(y_ho, et_pred)\n",
    "    f1 = f1_score(y_ho, et_pred)\n",
    "    accs_et.append(acc)\n",
    "    f1s_et.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b134a3f",
   "metadata": {},
   "source": [
    "Print out (average) accuracy scores and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d042e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"LogReg:   accuracy={sum(accs_logreg)/len(accs_logreg):.4f}, F1={sum(f1s_logreg)/len(f1s_logreg):.4f}\")\n",
    "print(f\"Tree:     accuracy={sum(accs_tree)/len(accs_tree):.4f}, F1={sum(f1s_tree)/len(f1s_tree):.4f}\")\n",
    "print(f\"RF:       accuracy={sum(accs_rf)/len(accs_rf):.4f}, F1={sum(f1s_rf)/len(f1s_rf):.4f}\")\n",
    "print(f\"ET:       accuracy={sum(accs_et)/len(accs_et):.4f}, F1={sum(f1s_et)/len(f1s_et):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoax-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
