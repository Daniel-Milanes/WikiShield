{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55fd5a6",
   "metadata": {},
   "source": [
    "# Cluebot - Modeling - Bayes-based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36624b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91fe6430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EditType</th>\n",
       "      <th>EditID</th>\n",
       "      <th>comment</th>\n",
       "      <th>user</th>\n",
       "      <th>user_edit_count</th>\n",
       "      <th>user_distinct_pages</th>\n",
       "      <th>user_warns</th>\n",
       "      <th>user_reg_time</th>\n",
       "      <th>prev_user</th>\n",
       "      <th>common</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_timestamp</th>\n",
       "      <th>deleted_lines</th>\n",
       "      <th>isvandalism</th>\n",
       "      <th>num_edits_5d_before</th>\n",
       "      <th>is_person</th>\n",
       "      <th>comment_empty</th>\n",
       "      <th>account_age</th>\n",
       "      <th>is_IP</th>\n",
       "      <th>word_count_added</th>\n",
       "      <th>word_count_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13216</th>\n",
       "      <td>change</td>\n",
       "      <td>229473995</td>\n",
       "      <td>/* Modern astronomers */</td>\n",
       "      <td>93.96.38.200</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>20080802214649</td>\n",
       "      <td>Jason Patton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1217286609</td>\n",
       "      <td>\"Contrary to the classical image of an old ast...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14501</th>\n",
       "      <td>change</td>\n",
       "      <td>230012102</td>\n",
       "      <td>/* Filmography */</td>\n",
       "      <td>86.4.18.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20080805163143</td>\n",
       "      <td>TheYoungDoctor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1216983053</td>\n",
       "      <td>==Filmography==,</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284</th>\n",
       "      <td>change</td>\n",
       "      <td>327880970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jack1956</td>\n",
       "      <td>102118</td>\n",
       "      <td>15619</td>\n",
       "      <td>2</td>\n",
       "      <td>1179350131</td>\n",
       "      <td>Jack1956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1259165771</td>\n",
       "      <td>\"He appeared in the original [[Broadway]] prod...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>923</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21789</th>\n",
       "      <td>change</td>\n",
       "      <td>230508181</td>\n",
       "      <td>[[WP:AES|←]] Replaced content with '\\nYou is a...</td>\n",
       "      <td>4.246.210.114</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080807234526</td>\n",
       "      <td>J.delanoy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1218152552</td>\n",
       "      <td>{{Refimprove|date=October 2007}},{{OR|date=Mar...</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10893</th>\n",
       "      <td>change</td>\n",
       "      <td>328717972</td>\n",
       "      <td>/* \"Red Data\" */</td>\n",
       "      <td>Mc53912</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1120465072</td>\n",
       "      <td>Mc53912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1259548893</td>\n",
       "      <td>\"In ''X-Men'' #197, While the team rushed Rogu...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1609</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EditType     EditID                                            comment  \\\n",
       "13216   change  229473995                           /* Modern astronomers */   \n",
       "14501   change  230012102                                  /* Filmography */   \n",
       "15284   change  327880970                                                NaN   \n",
       "21789   change  230508181  [[WP:AES|←]] Replaced content with '\\nYou is a...   \n",
       "10893   change  328717972                                   /* \"Red Data\" */   \n",
       "\n",
       "                user  user_edit_count  user_distinct_pages  user_warns  \\\n",
       "13216   93.96.38.200                9                    7           0   \n",
       "14501     86.4.18.29                1                    1           0   \n",
       "15284       Jack1956           102118                15619           2   \n",
       "21789  4.246.210.114                3                    2           2   \n",
       "10893        Mc53912               45                    7           0   \n",
       "\n",
       "        user_reg_time       prev_user  common  ...  previous_timestamp  \\\n",
       "13216  20080802214649    Jason Patton     NaN  ...          1217286609   \n",
       "14501  20080805163143  TheYoungDoctor     NaN  ...          1216983053   \n",
       "15284      1179350131        Jack1956     NaN  ...          1259165771   \n",
       "21789  20080807234526       J.delanoy     NaN  ...          1218152552   \n",
       "10893      1120465072         Mc53912     NaN  ...          1259548893   \n",
       "\n",
       "                                           deleted_lines  isvandalism  \\\n",
       "13216  \"Contrary to the classical image of an old ast...         True   \n",
       "14501                                   ==Filmography==,         True   \n",
       "15284  \"He appeared in the original [[Broadway]] prod...        False   \n",
       "21789  {{Refimprove|date=October 2007}},{{OR|date=Mar...         True   \n",
       "10893  \"In ''X-Men'' #197, While the team rushed Rogu...        False   \n",
       "\n",
       "      num_edits_5d_before is_person comment_empty  account_age  is_IP  \\\n",
       "13216                   2         0         False            1   True   \n",
       "14501                   0         1         False            1   True   \n",
       "15284                   2         1          True          923  False   \n",
       "21789                   8         0         False            1   True   \n",
       "10893                   2         0         False         1609  False   \n",
       "\n",
       "       word_count_added  word_count_deleted  \n",
       "13216               150                 150  \n",
       "14501                 2                   1  \n",
       "15284                51                  47  \n",
       "21789                32                 543  \n",
       "10893               140                 139  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from feature_engineer import preprocessor\n",
    "\n",
    "train_data = pd.read_csv('/Users/robin/Documents/GitHub/Cluebot/train_data.csv')\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "preprocessor.preprocessor(train_data)\n",
    "\n",
    "test_data = pd.read_csv('/Users/robin/Documents/GitHub/Cluebot/test_data.csv')\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3477ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.       , 0.       , 0.7759339])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "kfold = StratifiedKFold(n_splits,\n",
    "                           shuffle=True,\n",
    "                           random_state=498)\n",
    "\n",
    "features = ['user_edit_count', 'user_warns', 'user_distinct_pages', 'num_recent_edits', 'num_recent_reversions', 'current_minor', \\\n",
    "            'num_edits_5d_before', 'is_person', \\\n",
    "            'is_IP', 'account_age', 'comment_empty', 'word_count_added', 'word_count_deleted', \\\n",
    "            'added_lines', 'deleted_lines', 'EditID']\n",
    "\n",
    "from feature_engineer import preprocessor\n",
    "\n",
    "preprocessor.preprocessor(train_data)\n",
    "# train_data = train_data.reset_index(drop=True)\n",
    "train_data.sample(5)\n",
    "\n",
    "from feature_engineer import vandalism_scorer as vs\n",
    "\n",
    "# scorer = vs.VandalismScorer(n_splits=4, random_state=42)\n",
    "# scorer.fit(train_data, train_data['isvandalism'])\n",
    "\n",
    "bayes_accs = np.zeros((n_splits, 3))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(train_data, train_data['isvandalism'])):\n",
    "    edits_tt = train_data.iloc[train_index]\n",
    "    edits_ho = train_data.iloc[test_index]\n",
    "\n",
    "    model_pipe = Pipeline([('scorer', vs.VandalismScorer(n_splits = 5)), ('nb', GaussianNB())])\n",
    "\n",
    "    print(edits_tt.columns)\n",
    "    \n",
    "    ## Gaussian Naive Bayes\n",
    "    model_pipe.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    \n",
    "    nb_pred = model_pipe.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 2] = accuracy_score(edits_ho['isvandalism'], nb_pred)\n",
    "\n",
    "np.mean(bayes_accs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6948dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1628a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81654153, 0.79437394, 0.7759339 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayes-based Methods\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "features = ['user_edit_count', 'user_warns', 'user_distinct_pages', 'num_recent_edits', 'num_recent_reversions', 'current_minor', \\\n",
    "            'num_edits_5d_before', 'is_person', \\\n",
    "            'is_IP', 'account_age', 'comment_empty', 'word_count_added', 'word_count_deleted']\n",
    "\n",
    "bayes_accs = np.zeros((n_splits, 3))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(train_data, train_data['isvandalism'])):\n",
    "    edits_tt = train_data.iloc[train_index]\n",
    "    edits_ho = train_data.iloc[test_index]\n",
    "    \n",
    "    ## Linear Discriminant Analysis\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    lda.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    lda_pred = lda.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 0] = accuracy_score(edits_ho['isvandalism'], lda_pred)\n",
    "    \n",
    "    ## Quadratic Discriminant Analysis\n",
    "    qda = QuadraticDiscriminantAnalysis(store_covariance = True)\n",
    "    \n",
    "    qda.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    \n",
    "    qda_pred = qda.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 1] = accuracy_score(edits_ho['isvandalism'], qda_pred)\n",
    "    \n",
    "    \n",
    "    ## Gaussian Naive Bayes\n",
    "    nb = GaussianNB()\n",
    "    \n",
    "    nb.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    \n",
    "    nb_pred = nb.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 2] = accuracy_score(edits_ho['isvandalism'], nb_pred)\n",
    "\n",
    "np.mean(bayes_accs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "227efed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Do a cross validation split manually\n",
    "total_indices = list(range(len(train_data))) # \n",
    "random.shuffle(total_indices)\n",
    "fold = [[], [], [], [], []]\n",
    "[fold[0], fold[1], fold[2], fold[3], fold[4]] = np.array_split(total_indices, 5)\n",
    "for i in range(5):\n",
    "    fold[i] = list(fold[i])\n",
    "\n",
    "# Get the difference between two strings and return a set of words\n",
    "def get_difference(s1, s2):\n",
    "    w1 = set(re.sub(r\"[^\\w\\s]\", \" \", str(s1)).lower().split())\n",
    "    w2 = set(re.sub(r\"[^\\w\\s]\", \" \", str(s2)).lower().split())\n",
    "    return w1 - w2\n",
    "\n",
    "# Get a list of word probabilities using edits with given indices\n",
    "def get_word_prob(indices):\n",
    "    # Count the number of appearances of each word in vandalism/constructive edits\n",
    "    vandalism_words_count = defaultdict(int)\n",
    "    constructive_words_count = defaultdict(int)\n",
    "    \n",
    "    for i in indices:\n",
    "        for word in get_difference(str(train_data.loc[i, 'added_lines']), str(train_data.loc[i, 'deleted_lines'])):\n",
    "            if train_data['isvandalism'][i] == True:\n",
    "                vandalism_words_count[word] += 1\n",
    "            else:\n",
    "                constructive_words_count[word] += 1\n",
    "\n",
    "    # Combine all unique words\n",
    "    all_words = set(vandalism_words_count) | set(constructive_words_count)\n",
    "\n",
    "    # Compute smoothed probabilities\n",
    "    word_probs = {\n",
    "        word: (vandalism_words_count[word] + 1) / \n",
    "              (vandalism_words_count[word] + constructive_words_count[word] + 2)\n",
    "        for word in all_words\n",
    "    }\n",
    "    return word_probs\n",
    "\n",
    "# Compute vandalism scores for edits with given indices using a given list of word probabilities \n",
    "def compute_vandalism_scores(word_probs, indices):\n",
    "    for i in indices:\n",
    "        words = get_difference(train_data['added_lines'][i], train_data['deleted_lines'][i])\n",
    "        probs_of_words = [word_probs.get(w, 0.5) for w in words]\n",
    "\n",
    "        product_p = 1\n",
    "        product_1_minus_p = 1\n",
    "        for p in probs_of_words:\n",
    "            product_p *= p\n",
    "            product_1_minus_p *= (1-p)\n",
    "        \n",
    "        score = product_p / (product_p + product_1_minus_p) if (product_p + product_1_minus_p) != 0 else 1\n",
    "        train_data.loc[i, 'vandalism_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68107b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1497 1117]\n",
      " [  15 2468]]\n",
      "[[1550 1164]\n",
      " [  22 2362]]\n",
      "[[1473 1127]\n",
      " [  18 2480]]\n",
      "[[1532 1091]\n",
      " [  13 2462]]\n",
      "[[1417 1123]\n",
      " [  16 2541]]\n",
      "0.7761300291796965\n"
     ]
    }
   ],
   "source": [
    "# Modified Stacking Classifier Method\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for i in range(5):\n",
    "    i_0 = i % 5\n",
    "    i_1 = (i + 1) % 5\n",
    "    i_2 = (i + 2) % 5\n",
    "    i_3 = (i + 3) % 5\n",
    "    i_4 = (i + 4) % 5\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_1] + fold[i_2] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_0])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_2] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_1])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_1] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_2])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_1] + fold[i_2])\n",
    "    compute_vandalism_scores(word_probs, fold[i_3])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_1] + fold[i_2] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_4])\n",
    "\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(train_data.loc[fold[i_0] + fold[i_1] + fold[i_2] + fold[i_3], features], train_data.loc[fold[i_0] + fold[i_1] + fold[i_2] + fold[i_3], 'isvandalism'])\n",
    "    pred = nb.predict(train_data.loc[fold[i_4], features])\n",
    "\n",
    "    accuracy_scores.append(np.sum(pred == train_data.loc[fold[i_4], 'isvandalism'])/len(train_data.loc[fold[i_4], 'isvandalism']))\n",
    "    print(confusion_matrix(train_data.loc[fold[i_4], 'isvandalism'], pred))\n",
    "\n",
    "print(np.average(accuracy_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
