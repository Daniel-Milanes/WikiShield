{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55fd5a6",
   "metadata": {},
   "source": [
    "# Cluebot - Modeling - Bayes-based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36624b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91fe6430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EditType</th>\n",
       "      <th>EditID</th>\n",
       "      <th>comment</th>\n",
       "      <th>user</th>\n",
       "      <th>user_edit_count</th>\n",
       "      <th>user_distinct_pages</th>\n",
       "      <th>user_warns</th>\n",
       "      <th>user_reg_time</th>\n",
       "      <th>prev_user</th>\n",
       "      <th>common</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_timestamp</th>\n",
       "      <th>deleted_lines</th>\n",
       "      <th>isvandalism</th>\n",
       "      <th>num_edits_5d_before</th>\n",
       "      <th>is_person</th>\n",
       "      <th>comment_empty</th>\n",
       "      <th>account_age</th>\n",
       "      <th>is_IP</th>\n",
       "      <th>word_count_added</th>\n",
       "      <th>word_count_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>change</td>\n",
       "      <td>327600301</td>\n",
       "      <td>Revert to revision 325173076 dated 2009-11-11 ...</td>\n",
       "      <td>Debivort</td>\n",
       "      <td>11002</td>\n",
       "      <td>3256</td>\n",
       "      <td>0</td>\n",
       "      <td>1116059808</td>\n",
       "      <td>142.104.9.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1259024011</td>\n",
       "      <td>\"Sandar are most common in [[Iceland]], where ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1654</td>\n",
       "      <td>False</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>change</td>\n",
       "      <td>253005674</td>\n",
       "      <td>Added Rio Ashcfroft to the list because thay i...</td>\n",
       "      <td>79.79.1.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20081120163623</td>\n",
       "      <td>Gibson Flying V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1225359235</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>change</td>\n",
       "      <td>231355099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.234.150.172</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20080812013501</td>\n",
       "      <td>Kirby13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1218501868</td>\n",
       "      <td>| Birth_name          = Paul Kevin Jonas II</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>change</td>\n",
       "      <td>327229797</td>\n",
       "      <td>[[WP:UNDO|Undid]] revision 327150558 by [[Spec...</td>\n",
       "      <td>Goodraise</td>\n",
       "      <td>15957</td>\n",
       "      <td>4079</td>\n",
       "      <td>0</td>\n",
       "      <td>1182244481</td>\n",
       "      <td>89.134.154.238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1258830793</td>\n",
       "      <td>\"A number of musical CDs have been created. Va...</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>886</td>\n",
       "      <td>False</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16853</th>\n",
       "      <td>change</td>\n",
       "      <td>329049847</td>\n",
       "      <td>Delink dates ([[WP:MOSUNLINKDATES]]) using [[P...</td>\n",
       "      <td>Rich Farmbrough</td>\n",
       "      <td>1712760</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1083530056</td>\n",
       "      <td>Numbo3-bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1254606641</td>\n",
       "      <td>{{Infobox Planet ,\"| discovered = [[September ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2038</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EditType     EditID                                            comment  \\\n",
       "7497    change  327600301  Revert to revision 325173076 dated 2009-11-11 ...   \n",
       "22875   change  253005674  Added Rio Ashcfroft to the list because thay i...   \n",
       "1299    change  231355099                                                NaN   \n",
       "18574   change  327229797  [[WP:UNDO|Undid]] revision 327150558 by [[Spec...   \n",
       "16853   change  329049847  Delink dates ([[WP:MOSUNLINKDATES]]) using [[P...   \n",
       "\n",
       "                  user  user_edit_count  user_distinct_pages  user_warns  \\\n",
       "7497          Debivort            11002                 3256           0   \n",
       "22875       79.79.1.85                1                    1           0   \n",
       "1299    96.234.150.172                1                    1           0   \n",
       "18574        Goodraise            15957                 4079           0   \n",
       "16853  Rich Farmbrough          1712760                    0          14   \n",
       "\n",
       "        user_reg_time        prev_user  common  ...  previous_timestamp  \\\n",
       "7497       1116059808     142.104.9.37     NaN  ...          1259024011   \n",
       "22875  20081120163623  Gibson Flying V     NaN  ...          1225359235   \n",
       "1299   20080812013501          Kirby13     NaN  ...          1218501868   \n",
       "18574      1182244481   89.134.154.238     NaN  ...          1258830793   \n",
       "16853      1083530056       Numbo3-bot     NaN  ...          1254606641   \n",
       "\n",
       "                                           deleted_lines  isvandalism  \\\n",
       "7497   \"Sandar are most common in [[Iceland]], where ...        False   \n",
       "22875                                                 \"\"         True   \n",
       "1299         | Birth_name          = Paul Kevin Jonas II         True   \n",
       "18574  \"A number of musical CDs have been created. Va...        False   \n",
       "16853  {{Infobox Planet ,\"| discovered = [[September ...        False   \n",
       "\n",
       "      num_edits_5d_before is_person comment_empty  account_age  is_IP  \\\n",
       "7497                    1         0         False         1654  False   \n",
       "22875                   0         0         False            1   True   \n",
       "1299                   24         1          True            1   True   \n",
       "18574                  14         0         False          886  False   \n",
       "16853                   0         0         False         2038  False   \n",
       "\n",
       "       word_count_added  word_count_deleted  \n",
       "7497                 48                  48  \n",
       "22875                 5                   0  \n",
       "1299                  5                   5  \n",
       "18574                62                  64  \n",
       "16853                41                  41  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from feature_engineer import preprocessor\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('../Data/train.csv')\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "preprocessor(train_data)\n",
    "\n",
    "test_data = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3477ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n",
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.77658478])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "kfold = StratifiedKFold(n_splits,\n",
    "                           shuffle=True,\n",
    "                           random_state=498)\n",
    "\n",
    "features = ['user_edit_count', 'user_warns', 'user_distinct_pages', 'num_recent_edits', 'num_recent_reversions', 'current_minor', \\\n",
    "            'num_edits_5d_before', 'is_person', \\\n",
    "            'is_IP', 'account_age', 'comment_empty', 'word_count_added', 'word_count_deleted', \\\n",
    "            'added_lines', 'deleted_lines', 'EditID']\n",
    "\n",
    "preprocessor(train_data)\n",
    "# train_data = train_data.reset_index(drop=True)\n",
    "# train_data.sample(5)\n",
    "\n",
    "from feature_engineer import vandalism_scorer as vs\n",
    "\n",
    "# scorer = vs.VandalismScorer(n_splits=4, random_state=42)\n",
    "# scorer.fit(train_data, train_data['isvandalism'])\n",
    "\n",
    "bayes_accs = np.zeros((n_splits, 3))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(train_data, train_data['isvandalism'])):\n",
    "    edits_tt = train_data.iloc[train_index]\n",
    "    edits_ho = train_data.iloc[test_index]\n",
    "\n",
    "    model_pipe = Pipeline([('scorer', vs.VandalismScorer(n_splits = n_splits-1, random_state=498)), ('nb', GaussianNB())])\n",
    "\n",
    "    print(edits_tt.columns)\n",
    "    \n",
    "    ## Gaussian Naive Bayes\n",
    "    model_pipe.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    \n",
    "    nb_pred = model_pipe.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 2] = accuracy_score(edits_ho['isvandalism'], nb_pred)\n",
    "\n",
    "np.mean(bayes_accs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1628a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EditType', 'EditID', 'comment', 'user', 'user_edit_count',\n",
      "       'user_distinct_pages', 'user_warns', 'user_reg_time', 'prev_user',\n",
      "       'common', 'current', 'previous', 'page_made_time', 'title', 'namespace',\n",
      "       'creator', 'num_recent_edits', 'num_recent_reversions', 'current_minor',\n",
      "       'current_timestamp', 'added_lines', 'previous_timestamp',\n",
      "       'deleted_lines', 'isvandalism', 'num_edits_5d_before', 'is_person',\n",
      "       'comment_empty', 'account_age', 'is_IP', 'word_count_added',\n",
      "       'word_count_deleted'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81673741, 0.79510761, 0.77658478])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayes-based Methods\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "features = ['user_edit_count', 'user_warns', 'user_distinct_pages', 'num_recent_edits', 'num_recent_reversions', 'current_minor', \\\n",
    "            'num_edits_5d_before', 'is_person', \\\n",
    "            'is_IP', 'account_age', 'comment_empty', 'word_count_added', 'word_count_deleted']\n",
    "\n",
    "bayes_accs = np.zeros((n_splits, 3))\n",
    "print(train_data.columns)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(train_data, train_data['isvandalism'])):\n",
    "    edits_tt = train_data.iloc[train_index]\n",
    "    edits_ho = train_data.iloc[test_index]\n",
    "\n",
    "    ## Linear Discriminant Analysis\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    lda.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    lda_pred = lda.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 0] = accuracy_score(edits_ho['isvandalism'], lda_pred)\n",
    "    \n",
    "    ## Quadratic Discriminant Analysis\n",
    "    qda = QuadraticDiscriminantAnalysis(store_covariance = True)\n",
    "    \n",
    "    qda.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    \n",
    "    qda_pred = qda.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 1] = accuracy_score(edits_ho['isvandalism'], qda_pred)\n",
    "    \n",
    "    \n",
    "    ## Gaussian Naive Bayes\n",
    "    nb = GaussianNB()\n",
    "    \n",
    "    \n",
    "    nb.fit(edits_tt[features], edits_tt['isvandalism'])\n",
    "    \n",
    "    nb_pred = nb.predict(edits_ho[features])\n",
    "    \n",
    "    bayes_accs[i, 2] = accuracy_score(edits_ho['isvandalism'], nb_pred)\n",
    "\n",
    "np.mean(bayes_accs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "id": "502472d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30527820e+05, 4.02490660e+00, 3.82973529e+04, 6.25538845e-02,\n",
       "        1.24533001e-03, 2.65255293e-01, 8.56672095e+00, 2.33259891e-01,\n",
       "        3.02136220e-01, 6.77528307e+02, 2.15729476e-01, 1.10793946e+02,\n",
       "        1.01950762e+02, 2.59322172e-01],\n",
       "       [1.16486167e+02, 3.57936187e+00, 4.77551494e+01, 9.50121163e-02,\n",
       "        5.24030695e-02, 6.36106624e-03, 1.06901252e+01, 2.29907108e-01,\n",
       "        9.44163974e-01, 6.87520194e+00, 3.70759289e-01, 8.49193255e+01,\n",
       "        3.79863691e+02, 6.93946014e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe['nb'].theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9feb05dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.82599304e+11, 2.16226333e+02, 2.92661190e+10, 9.80187100e+01,\n",
       "        9.79538409e+01, 9.81474920e+01, 6.88950133e+02, 9.81314468e+01,\n",
       "        9.81634470e+01, 5.08075044e+05, 9.81217874e+01, 1.42393372e+05,\n",
       "        4.60397538e+05, 9.80146294e+01],\n",
       "       [6.20286876e+06, 1.43559990e+02, 8.13662686e+05, 9.81270310e+01,\n",
       "        9.80075045e+01, 9.79589177e+01, 9.41522063e+02, 9.81296469e+01,\n",
       "        9.80053155e+01, 5.25088916e+03, 9.81858939e+01, 1.90512252e+05,\n",
       "        1.83880162e+06, 9.80634178e+01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe['nb'].var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "227efed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Do a cross validation split manually\n",
    "total_indices = list(range(len(train_data))) # \n",
    "random.shuffle(total_indices)\n",
    "fold = [[], [], [], [], []]\n",
    "[fold[0], fold[1], fold[2], fold[3], fold[4]] = np.array_split(total_indices, 5)\n",
    "for i in range(5):\n",
    "    fold[i] = list(fold[i])\n",
    "\n",
    "# Get the difference between two strings and return a set of words\n",
    "def get_difference(s1, s2):\n",
    "    w1 = set(re.sub(r\"[^\\w\\s]\", \" \", str(s1)).lower().split())\n",
    "    w2 = set(re.sub(r\"[^\\w\\s]\", \" \", str(s2)).lower().split())\n",
    "    return w1 - w2\n",
    "\n",
    "# Get a list of word probabilities using edits with given indices\n",
    "def get_word_prob(indices):\n",
    "    # Count the number of appearances of each word in vandalism/constructive edits\n",
    "    vandalism_words_count = defaultdict(int)\n",
    "    constructive_words_count = defaultdict(int)\n",
    "    \n",
    "    for i in indices:\n",
    "        for word in get_difference(str(train_data.loc[i, 'added_lines']), str(train_data.loc[i, 'deleted_lines'])):\n",
    "            if train_data['isvandalism'][i] == True:\n",
    "                vandalism_words_count[word] += 1\n",
    "            else:\n",
    "                constructive_words_count[word] += 1\n",
    "\n",
    "    # Combine all unique words\n",
    "    all_words = set(vandalism_words_count) | set(constructive_words_count)\n",
    "\n",
    "    # Compute smoothed probabilities\n",
    "    word_probs = {\n",
    "        word: (vandalism_words_count[word] + 1) / \n",
    "              (vandalism_words_count[word] + constructive_words_count[word] + 2)\n",
    "        for word in all_words\n",
    "    }\n",
    "    return word_probs\n",
    "\n",
    "# Compute vandalism scores for edits with given indices using a given list of word probabilities \n",
    "def compute_vandalism_scores(word_probs, indices):\n",
    "    for i in indices:\n",
    "        words = get_difference(train_data['added_lines'][i], train_data['deleted_lines'][i])\n",
    "        probs_of_words = [word_probs.get(w, 0.5) for w in words]\n",
    "\n",
    "        product_p = 1\n",
    "        product_1_minus_p = 1\n",
    "        for p in probs_of_words:\n",
    "            product_p *= p\n",
    "            product_1_minus_p *= (1-p)\n",
    "        \n",
    "        score = product_p / (product_p + product_1_minus_p) if (product_p + product_1_minus_p) != 0 else 1\n",
    "        train_data.loc[i, 'vandalism_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68107b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1497 1117]\n",
      " [  15 2468]]\n",
      "[[1550 1164]\n",
      " [  22 2362]]\n",
      "[[1473 1127]\n",
      " [  18 2480]]\n",
      "[[1532 1091]\n",
      " [  13 2462]]\n",
      "[[1417 1123]\n",
      " [  16 2541]]\n",
      "0.7761300291796965\n"
     ]
    }
   ],
   "source": [
    "# Modified Stacking Classifier Method\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for i in range(5):\n",
    "    i_0 = i % 5\n",
    "    i_1 = (i + 1) % 5\n",
    "    i_2 = (i + 2) % 5\n",
    "    i_3 = (i + 3) % 5\n",
    "    i_4 = (i + 4) % 5\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_1] + fold[i_2] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_0])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_2] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_1])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_1] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_2])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_1] + fold[i_2])\n",
    "    compute_vandalism_scores(word_probs, fold[i_3])\n",
    "\n",
    "    word_probs = get_word_prob(fold[i_0] + fold[i_1] + fold[i_2] + fold[i_3])\n",
    "    compute_vandalism_scores(word_probs, fold[i_4])\n",
    "\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(train_data.loc[fold[i_0] + fold[i_1] + fold[i_2] + fold[i_3], features], train_data.loc[fold[i_0] + fold[i_1] + fold[i_2] + fold[i_3], 'isvandalism'])\n",
    "    pred = nb.predict(train_data.loc[fold[i_4], features])\n",
    "\n",
    "    accuracy_scores.append(np.sum(pred == train_data.loc[fold[i_4], 'isvandalism'])/len(train_data.loc[fold[i_4], 'isvandalism']))\n",
    "    print(confusion_matrix(train_data.loc[fold[i_4], 'isvandalism'], pred))\n",
    "\n",
    "print(np.average(accuracy_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoax-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
